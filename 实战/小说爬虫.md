### 目标：爬取零点看书网

 一本小说

### 1、爬取小说目录地址

爬取小说地址：https://www.lingdiankanshu.co/258400/

查看网页源代码

<img src="https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513103935.png" alt="image-20200512181300489"  />

小说`楔子`在一个id等于list的div下的dl下第二个dt的同级标签dd的a标签里面

用xpath来获取

```python
 a_list = html.xpath('//div[@id="list"]/dl/dt[2]/following-sibling::dd/a')
```

following-sibling :选取当前节点之后的所有同级节点 

获取章节地址和章节名

```python
pageUrlName_list = []
dit = {}
for a in a_list:
    dit['pageUrl'] = url + a.xpath('./@href')[0]
    dit['pageName'] = a.xpath('./text()')[0]
    pageUrlName_list.append(dit.copy())
print(pageUrlName_list)
```
![image-20200513091309576](https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513091311.png)

### 2、爬取小说内容页

![image-20200512174456118](https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513094057.png)

小说内容在一个id等于content的div里面

获取小说内容：

```python 
content_list = html.xpath('//div[@id="content"]/text()')
print(content_list)
```

![image-20200512175215469](https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513094107.png)

### 3、整理爬取的小说

```python
content = '\r\n'.join(content_list[:-1])
print(content)
```

![image-20200512180442575](https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513094116.png)

### 4、多线程下载

由于小说各个章节顺序一定，可以定义一个正在保存章节的标记

```python
index = 0
```

把章节地址扔进队列中，用的时候取出来

```python
from queue import Queue
q = Queue()
# i记录章节顺序
for i, page in enumerate(pageUrlName_list):
	q.put([i, page])
```

当队列不为空时：从队列中取出一个元素

```python
while not q.empty():
    i, page_url_name = q.get()
```

判断当前爬取的章节是否和保存标记的章节数一样

不一样：等待

```python
 while i > index:
 	pass
```

一样：保存当前章节，用来保存标记的章节数加一

```python
if index == i:
    fw.write(content)
    index += 1
```

开始多线程：

```python
ts = []
for i in range(10):
    t = Thread(target=down_txt, args=[q, fw])
    t.start()
    ts.append(t)

for t in ts:
    t.join()
```

### 5、完整代码：

```python
import requests
from lxml import etree
from queue import Queue
from threading import Thread


headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36 Edg/81.0.416.72',
}


def get_pageUrlName(url):
    '''获取各章节地址和章节名'''
    resp = requests.get(url, headers=headers)
    html = etree.HTML(resp.text)
    dd_list = html.xpath('//div[@id="list"]/dl/dt[2]/following-sibling::dd')
    # 获取小说名
    title = html.xpath('//h1/text()')[0]
    pageUrlName_list = []
    dit = {}
    for dd in dd_list:

        dit['pageUrl'] = url + dd.xpath('./a/@href')[0]
        dit['pageName'] = dd.xpath('./a/text()')[0]
        pageUrlName_list.append(dit.copy())

    # print(pageUrlName_list)
    return pageUrlName_list, title


def get_content(page_url):
    '''获取内容'''
    resp = requests.get(page_url, headers=headers)
    html = etree.HTML(resp.text)
    content_list = html.xpath('//div[@id="content"]/text()')
    # print('\r\n'.join(content_list[:-1]))
    return '\r\n'.join(content_list[:-1])


def down_txt(q, fw):
    '''保存小说'''
    global index
    while not q.empty():
        i, page_url_name = q.get()
        # print(page_url_name, i)
        page_url = page_url_name['pageUrl']
        page_name = page_url_name['pageName']
        content = page_name + get_content(page_url)
        print('爬取-->', page_name)

        # 判断当前章节是否和标记的章节数一样
        while i > index:
            pass

        if index == i:
            print('保存-->', page_name)
            fw.write(content)
            index += 1


if __name__ == '__main__':
    url = 'https://www.lingdiankanshu.co/467479/'
    pageUrl_list, title = get_pageUrlName(url)
    # print(pageUrl_list)
    
    q = Queue()
    for i, page_url_name in enumerate(pageUrl_list):
        q.put([i, page_url_name])

    index = 0   # 记录保存章节数
    with open(f'{title}.txt', 'w', encoding='utf8') as fw:

        ts = []
        for i in range(10):
            t = Thread(target=down_txt, args=[q, fw])
            t.start()
            ts.append(t)

        for t in ts:
            t.join()

```

![image-20200513100343826](https://raw.githubusercontent.com/2663481911/picGo_img/master/20200513103918.png)